{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd16bf63-e689-45ab-a1f9-417d4c193824",
   "metadata": {},
   "source": [
    "# Langgraph 2: Graph with Interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c41e3-a3e4-4790-9686-3585a8a85c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########  LangGraph  ##########################\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "import panel as pn\n",
    "from typing import TypedDict, Annotated, List, Sequence\n",
    "from IPython.display import display, Markdown,Latex,Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1386c3-35d6-46c0-9995-6868e5b52c12",
   "metadata": {},
   "source": [
    "# Graph with interrupt\n",
    "\n",
    "https://towardsdatascience.com/from-basics-to-advanced-exploring-langgraph-e8c1cf4db787\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67fca2d-9908-4019-b154-4c0def9a9687",
   "metadata": {},
   "source": [
    "This code defines a simple graph-based flow using nodes, states, and transitions between them, with each node performing a specific task in sequence. Here's a breakdown of the code:\n",
    "\n",
    "### 1. **State Definition**\n",
    "\n",
    "   ```python\n",
    "   class State(TypedDict):\n",
    "       input: str\n",
    "       messages: Annotated[list, add_messages]\n",
    "   ```\n",
    "   - `State` is a custom data structure using `TypedDict` to define the types of state properties.\n",
    "   - It has two fields:\n",
    "     - `input`: a string input, likely used for carrying initial data.\n",
    "     - `messages`: a list of messages, annotated for additional behavior, presumably where the flow can accumulate or modify output messages as it progresses through nodes.\n",
    "\n",
    "### 2. **Node Functions**\n",
    "\n",
    "   - Each node function (`node1`, `node2`, `node3`) modifies the `state` and then returns it. Each function performs the following:\n",
    "\n",
    "     - **`node1`**: Starts by printing \"Start node1\" and sets `state[\"messages\"]` to `[\"Output node1: I wanna go home\"]`.\n",
    "     - **`node2`**: Starts by printing \"Start node2\" and sets `state[\"messages\"]` to `[\"Output node2: What's the problem with node1?\"]`.\n",
    "     - **`node3`**: Starts by printing \"Start node3\" and sets `state[\"messages\"]` to `[\"node3: I am going home\"]`.\n",
    "\n",
    "   - Each node is designed to sequentially alter `state[\"messages\"]` with a unique message.\n",
    "\n",
    "### 3. **StateGraph Creation**\n",
    "\n",
    "   ```python\n",
    "   builder = StateGraph(State)\n",
    "   builder.add_node(\"node1\", node1)\n",
    "   builder.add_node(\"node2\", node2)\n",
    "   builder.add_node(\"node3\", node3)\n",
    "   builder.set_entry_point(\"node1\")\n",
    "   ```\n",
    "   - `StateGraph` is initialized with the `State` structure, which defines the state format that each node will manipulate.\n",
    "   - Nodes `node1`, `node2`, and `node3` are added to the graph with corresponding functions.\n",
    "   - `set_entry_point(\"node1\")` designates `node1` as the starting point of the graph.\n",
    "\n",
    "### 4. **Defining the Flow (Edges)**\n",
    "\n",
    "   ```python\n",
    "   builder.add_edge(\"node1\", \"node2\")\n",
    "   builder.add_edge(\"node2\", \"node3\")\n",
    "   builder.add_edge(\"node3\", END)\n",
    "   ```\n",
    "   - These edges define the sequence in which nodes execute:\n",
    "     - After `node1`, the flow proceeds to `node2`.\n",
    "     - After `node2`, it moves to `node3`.\n",
    "     - After `node3`, the process ends (`END`).\n",
    "\n",
    "### 5. **Memory Setup and Graph Compilation**\n",
    "\n",
    "   ```python\n",
    "   memory = MemorySaver()\n",
    "   graph = builder.compile(checkpointer=memory, interrupt_before=[\"node3\"])\n",
    "   ```\n",
    "   - `MemorySaver()` is set up to track the state across the nodes, storing each step in memory.\n",
    "   - `interrupt_before=[\"node3\"]` indicates an interruption before `node3` executes, perhaps to review or change the state.\n",
    "\n",
    "### 6. **Visualization of the Graph**\n",
    "\n",
    "   ```python\n",
    "   display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "   ```\n",
    "   - Finally, the code generates and displays a graphical representation of the flow using `Mermaid` notation. Each node and edge of the graph will be displayed, showing how the flow progresses from `node1` to `node2` to `node3`.\n",
    "\n",
    "### Summary\n",
    "\n",
    "This code builds a simple stateful flow where:\n",
    "- **Each node** changes the `state[\"messages\"]`.\n",
    "- **Flow** goes from `node1` ➔ `node2` ➔ `node3`.\n",
    "- **Memory and interruption** allow state tracking and intervention before the final node.\n",
    "- **Graph visualization** shows the flow for easier comprehension and debugging. \n",
    "\n",
    "This setup can be particularly useful in chatbot flows, decision trees, or automated process orchestration scenarios where states change sequentially through nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1f2f9-f003-49a0-b534-0b188f1484d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def node1(state:State):\n",
    "    latest_message = state[\"messages\"][-1] if state[\"messages\"] else \"No messages\"\n",
    "    print(f\"Start node1 with latest message: {latest_message}\")\n",
    "    return {'messages' : \"Here is some code\" }\n",
    "\n",
    "\n",
    "def node2(state:State):\n",
    "    latest_message = state[\"messages\"][-1] if state[\"messages\"] else \"No messages\"\n",
    "    print(f\"Start node2 with latest message: {latest_message}\")\n",
    "    return {'messages' : \"here is some more code\" }\n",
    "\n",
    "\n",
    "def node3(state:State):\n",
    "    latest_message = state[\"messages\"][-1] if state[\"messages\"] else \"No messages\"\n",
    "    print(f\"Start node3 with latest message: {latest_message}\")\n",
    "    state[\"messages\"]=[\"node3: I am going home\"]\n",
    "    return state \n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node1\", node1)\n",
    "builder.set_entry_point(\"node1\")\n",
    "builder.add_node(\"node2\", node2)\n",
    "builder.add_edge(\"node1\", \"node2\")\n",
    "from langgraph.types import interrupt, Command\n",
    "def human_node(state: State):\n",
    "    value = interrupt( \n",
    "        {\n",
    "            \"text_to_revise\": state[\"messages\"][-1] if state[\"messages\"] else \"No messages\",\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": \"this is the human response\" \n",
    "    }\n",
    "builder.add_node(\"human_node\", human_node)\n",
    "builder.add_edge(\"node2\", \"human_node\")\n",
    "builder.add_node(\"node3\", node3)\n",
    "builder.add_edge(\"human_node\", \"node3\")\n",
    "builder.add_edge(\"node3\", END)\n",
    "\n",
    "# Set up memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Add\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba201d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging_config.logger import LOG\n",
    "from langgraph.types import Command, interrupt\n",
    "thread = {\"configurable\": {\"thread_id\": \"3\"}}  \n",
    "def input_function(question:str, thread : dict = thread):\n",
    "    input = {\"input\": question}\n",
    "    out=[]\n",
    "    current_state = graph.get_state(thread).values\n",
    "    LOG.info(f\"Current state before invoking graph: {current_state}\")\n",
    "    graph.update_state(thread,current_state)\n",
    "    response = graph.invoke(input, thread )\n",
    "    if response[\"messages\"]:\n",
    "        out.append(response[\"messages\"][-1].content)\n",
    "    # for state in graph.stream(input, thread, stream_mode=\"values\"):\n",
    "    #     out.append(state[\"messages\"][-1].content)  \n",
    "    LOG.info(f'Response from input function: {response}')\n",
    "    answer=\"Graph : \"+ \"\\n\".join(out)\n",
    "    print(\"Input_function : \\n\",answer)\n",
    "    print('------')\n",
    "    return answer\n",
    "from langchain_core.messages import HumanMessage  # Make sure this is imported\n",
    "\n",
    "def resume_function(human_response: str, thread: dict = thread):\n",
    "    # Wrap the user response in a HumanMessage as expected by LangGraph\n",
    "    human_message = HumanMessage(content=human_response)\n",
    "    \n",
    "    # Create a resumable command with the message\n",
    "    human_command = Command(resume={\"messages\": [human_message]})\n",
    "    \n",
    "    # Invoke the graph with the resumable input\n",
    "    response = graph.invoke(human_command, thread)\n",
    "    \n",
    "    out = []\n",
    "    if response[\"messages\"]:\n",
    "        out.append(response[\"messages\"][-1].content)\n",
    "    \n",
    "    LOG.info(f'Response from resume function: {response}')\n",
    "    answer = \"Graph after resume: \" + \"\\n\".join(out)\n",
    "    print(\"Resume_function : \\n\", answer)\n",
    "    print('------')\n",
    "    return answer\n",
    "\n",
    "        \n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "question = pn.widgets.TextInput(name=\"Input here please\", placeholder=\"Task\", sizing_mode=\"stretch_width\")\n",
    "output = pn.pane.Markdown(\"Answer\")  # This will display the answer text\n",
    "question = pn.widgets.TextInput(name=\"Input here please\", placeholder=\"Task\", sizing_mode=\"stretch_width\")\n",
    "output = pn.pane.Markdown(\"Answer\")\n",
    "answer_button = pn.widgets.Button(name=\"Answer\", button_type=\"primary\", width=50, height=50)\n",
    "\n",
    "\n",
    "\n",
    "def button_click(event):\n",
    "    print(f'number of clicks: {answer_button.clicks}')\n",
    "    if answer_button.clicks == 1:\n",
    "        bound_function = pn.bind(input_function, question)\n",
    "        output.object = f\"Answer:\\n {bound_function()}\"\n",
    "    if answer_button.clicks > 1:\n",
    "        bound_function = pn.bind(resume_function, question)\n",
    "        output.object = f\"Answer after resume:\\n {bound_function()}\"\n",
    "\n",
    "answer_button.on_click(button_click)\n",
    "\n",
    "Tab = pn.Column(\n",
    "    pn.Row(question),\n",
    "    pn.panel(answer_button, loading_indicator=True, height=50),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(output, loading_indicator=True, height=900),\n",
    "    sizing_mode=\"stretch_width\"\n",
    ")\n",
    "\n",
    "layout = pn.Column(pn.Tabs(('Answer', Tab)))\n",
    "layout.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feab229",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752003be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a168f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motion-canvas-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
